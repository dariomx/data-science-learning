\begin{frame}[plain]
	\frametitle{Enter tensors [Symonds11]}
	\begin{block}{}
    Models of word meaning, built from a corpus of text, have
    demonstrated success in emulating human performance on a number of
    cognitive 
    tasks. Many of these models use geometric representations of words to
    store semantic associations between words. Often word order
    information is not captured in these models. The lack of structural
    information used by these models has been raised as a weakness when
    performing cognitive tasks.
    This paper presents an efficient tensor based approach to modelling
    word meaning that builds on recent attempts to encode word order
    information, while providing flexible methods for extracting task
    specific semantic information.
	\end{block} 
\end{frame}
